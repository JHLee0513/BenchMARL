defaults:
  - mbpo_config
  - _self_

# MASAC backbone defaults
share_param_critic: True
num_qvalue_nets: 2
loss_function: "l2"
delay_qvalue: True
target_entropy: "auto"
discrete_target_entropy_weight: 0.2
alpha_init: 1.0
min_alpha: null
max_alpha: null
fixed_alpha: False
scale_mapping: "biased_softplus_1.0"
use_tanh_normal: True
coupled_discrete_values: True

# MBPO-specific knobs
warmup_steps: 2500 # Number of steps to train the model for before using it to sample synthetic rollout
rollout_horizon: 10
model_train_freq: 1
ensemble_size: 5
# Number of elite models to sample from during rollouts (defaults to all if null)
n_elites: null
model_batch_size: 256
# Mixing / batch sizing:
# - If `syn_ratio` is null: backward-compatible behavior (real_ratio is a fraction, synthetic ~= (1-real_ratio)).
# - If `syn_ratio` is set: new behavior (multipliers of the baseline minibatch size):
#     n_real  ~= real_ratio * batch_size
#     n_synth ~= syn_ratio  * batch_size
real_ratio: 0.5
syn_ratio: null
temperature: 1.0
model_lr: 0.001
model_hidden_size: 256
model_num_layers: 2
reward_loss_coef: 1.0
# Scaling coefficient for log-variance term in NLL loss. 
# Lower values (e.g., 0.5) prevent the model from exploiting high uncertainty to make loss negative.
# Default: 1.0 (standard NLL), but 0.5 is often more stable.
logvar_loss_coef: 0.5
reward_normalize: False
state_normalize: False
separate_reward_net: False
stochastic_dynamics: True
min_log_var: -10.0
max_log_var: -2.0

# If True, learn a single centralized world model per agent-group that predicts the
# joint next observation given the joint observation and all agents' actions.
centralized_dynamics: False

# Path to a pretrained world model to load (set to null to train from scratch)
load_world_model_path: null
# If True, raise an error if loaded config doesn't match current config.
# If False, only load model parameters and optimizers.
load_world_model_strict: True
# Path where to automatically save the world model (set to null to disable auto-saving)
save_world_model_path: null
# Interval (in training steps) for automatic world model saving. 
# If null, saves after each training step. Set to a positive integer to save periodically.
save_world_model_interval: null


